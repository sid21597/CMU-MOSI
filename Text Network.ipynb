{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d1e289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b61c9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4699c58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\CMUSUER\\Text\\Training.csv\")\n",
    "train = []\n",
    "train_labels = []\n",
    "for i in range(len(df)):\n",
    "    train.append(df.iloc[i][2])\n",
    "    train_labels.append(df.iloc[i][3])\n",
    "df = pd.read_csv(\"D:\\CMUSUER\\Text\\Valid.csv\")   \n",
    "valid = []\n",
    "valid_labels = []\n",
    "for i in range(len(df)):\n",
    "    valid.append(df.iloc[i][3])\n",
    "    valid_labels.append(df.iloc[i][4])\n",
    "df = pd.read_csv(\"D:\\CMUSUER\\Text\\Test.csv\")   \n",
    "test = []\n",
    "test_labels = []\n",
    "for i in range(len(df)):\n",
    "    test.append(df.iloc[i][3])\n",
    "    test_labels.append(df.iloc[i][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bbcf7eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 30000\n",
    "embedding_dim = 32\n",
    "max_length = 100\n",
    "trunc_type = 'post'\n",
    "oov_tok = \"<OOV>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "94dc29b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "train = np.asarray(train)\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(train)\n",
    "word_index = tokenizer.word_index\n",
    "train_sequences = tokenizer.texts_to_sequences(train)\n",
    "train_padded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "88136e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.asarray(test)\n",
    "valid  = np.asarray(valid)\n",
    "testing_sequences = tokenizer.texts_to_sequences(test)\n",
    "testing_padded = pad_sequences(testing_sequences,maxlen=max_length)\n",
    "valid_sequences = tokenizer.texts_to_sequences(valid)\n",
    "valid_padded = pad_sequences(valid_sequences,maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "427f600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "valid_labels = np.asarray(valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1c7e00db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 100, 32)           960000    \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection (None, 128)               37632     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 997,761\n",
      "Trainable params: 997,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64)),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "model.compile(loss='mse',optimizer='adam',metrics=['mse','mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "caa3ea89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.9411 - mse: 1.9411 - mae: 1.1889WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001615BC4EAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001615BC4EAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "41/41 [==============================] - 1s 32ms/step - loss: 1.9371 - mse: 1.9371 - mae: 1.1872 - val_loss: 3.4909 - val_mse: 3.4909 - val_mae: 1.4655\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 1.3995 - mse: 1.3995 - mae: 0.9657 - val_loss: 2.2190 - val_mse: 2.2190 - val_mae: 1.2298\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.9527 - mse: 0.9527 - mae: 0.7624 - val_loss: 2.1342 - val_mse: 2.1342 - val_mae: 1.1917\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.6776 - mse: 0.6776 - mae: 0.6276 - val_loss: 2.1357 - val_mse: 2.1357 - val_mae: 1.1782\n",
      "Epoch 5/20\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.5152 - mse: 0.5152 - mae: 0.5303 - val_loss: 2.1776 - val_mse: 2.1776 - val_mae: 1.1898\n",
      "Epoch 6/20\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.4241 - mse: 0.4241 - mae: 0.4686 - val_loss: 2.2517 - val_mse: 2.2517 - val_mae: 1.2011\n",
      "Epoch 7/20\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.3568 - mse: 0.3568 - mae: 0.4200 - val_loss: 2.2300 - val_mse: 2.2300 - val_mae: 1.1935\n",
      "Epoch 8/20\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.3154 - mse: 0.3154 - mae: 0.3928 - val_loss: 2.3115 - val_mse: 2.3115 - val_mae: 1.2168\n",
      "Epoch 9/20\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.2776 - mse: 0.2776 - mae: 0.3632 - val_loss: 2.3343 - val_mse: 2.3343 - val_mae: 1.2171\n",
      "Epoch 10/20\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.2475 - mse: 0.2475 - mae: 0.3342 - val_loss: 2.3600 - val_mse: 2.3600 - val_mae: 1.2280\n",
      "Epoch 11/20\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.2306 - mse: 0.2306 - mae: 0.3208 - val_loss: 2.3846 - val_mse: 2.3846 - val_mae: 1.2358\n",
      "Epoch 12/20\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.2119 - mse: 0.2119 - mae: 0.3027 - val_loss: 2.4515 - val_mse: 2.4515 - val_mae: 1.2484\n",
      "Epoch 13/20\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.1953 - mse: 0.1953 - mae: 0.2847 - val_loss: 2.4762 - val_mse: 2.4762 - val_mae: 1.2572\n",
      "Epoch 14/20\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.2025 - mse: 0.2025 - mae: 0.2998 - val_loss: 2.4873 - val_mse: 2.4873 - val_mae: 1.2716\n",
      "Epoch 15/20\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.1975 - mse: 0.1975 - mae: 0.2971 - val_loss: 2.4511 - val_mse: 2.4511 - val_mae: 1.2564\n",
      "Epoch 16/20\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.1752 - mse: 0.1752 - mae: 0.2737 - val_loss: 2.4917 - val_mse: 2.4917 - val_mae: 1.2623\n",
      "Epoch 17/20\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.1597 - mse: 0.1597 - mae: 0.2510 - val_loss: 2.5285 - val_mse: 2.5285 - val_mae: 1.2614\n",
      "Epoch 18/20\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.1488 - mse: 0.1488 - mae: 0.2355 - val_loss: 2.5084 - val_mse: 2.5084 - val_mae: 1.2690\n",
      "Epoch 19/20\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.1517 - mse: 0.1517 - mae: 0.2415 - val_loss: 2.5504 - val_mse: 2.5504 - val_mae: 1.2726\n",
      "Epoch 20/20\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.1428 - mse: 0.1428 - mae: 0.2342 - val_loss: 2.5494 - val_mse: 2.5494 - val_mae: 1.2718\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "history = model.fit(train_padded, train_labels, epochs=num_epochs, validation_data=(valid_padded, valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "85f56dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 100, 32)           960000    \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 256)               164864    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,125,121\n",
      "Trainable params: 1,125,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n",
    "    \n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "model.compile(loss='mse',optimizer='adam',metrics=['mse','mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "39446011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001613EE03558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001613EE03558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.2487 - mse: 2.2487 - mae: 1.3070WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001606A13CAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001606A13CAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "41/41 [==============================] - 2s 42ms/step - loss: 2.2487 - mse: 2.2487 - mae: 1.3070 - val_loss: 2.6533 - val_mse: 2.6533 - val_mae: 1.3940\n",
      "Epoch 2/15\n",
      "41/41 [==============================] - 1s 29ms/step - loss: 1.9711 - mse: 1.9711 - mae: 1.1990 - val_loss: 2.3278 - val_mse: 2.3278 - val_mae: 1.2994\n",
      "Epoch 3/15\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 1.2778 - mse: 1.2778 - mae: 0.9004 - val_loss: 2.1061 - val_mse: 2.1061 - val_mae: 1.1934\n",
      "Epoch 4/15\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.8604 - mse: 0.8604 - mae: 0.7219 - val_loss: 2.0466 - val_mse: 2.0466 - val_mae: 1.1612\n",
      "Epoch 5/15\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.6245 - mse: 0.6245 - mae: 0.5943 - val_loss: 2.0744 - val_mse: 2.0744 - val_mae: 1.1615\n",
      "Epoch 6/15\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.4920 - mse: 0.4920 - mae: 0.5164 - val_loss: 2.1810 - val_mse: 2.1810 - val_mae: 1.1981\n",
      "Epoch 7/15\n",
      "41/41 [==============================] - 1s 29ms/step - loss: 0.4087 - mse: 0.4087 - mae: 0.4585 - val_loss: 2.1687 - val_mse: 2.1687 - val_mae: 1.1752\n",
      "Epoch 8/15\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.3604 - mse: 0.3604 - mae: 0.4278 - val_loss: 2.2646 - val_mse: 2.2646 - val_mae: 1.2175\n",
      "Epoch 9/15\n",
      "41/41 [==============================] - 1s 30ms/step - loss: 0.3288 - mse: 0.3288 - mae: 0.4093 - val_loss: 2.1953 - val_mse: 2.1953 - val_mae: 1.1941\n",
      "Epoch 10/15\n",
      "41/41 [==============================] - 1s 30ms/step - loss: 0.2901 - mse: 0.2901 - mae: 0.3768 - val_loss: 2.2078 - val_mse: 2.2078 - val_mae: 1.2006\n",
      "Epoch 11/15\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.2644 - mse: 0.2644 - mae: 0.3512 - val_loss: 2.1718 - val_mse: 2.1718 - val_mae: 1.1936\n",
      "Epoch 12/15\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.2359 - mse: 0.2359 - mae: 0.3253 - val_loss: 2.2624 - val_mse: 2.2624 - val_mae: 1.2182\n",
      "Epoch 13/15\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.2233 - mse: 0.2233 - mae: 0.3169 - val_loss: 2.2689 - val_mse: 2.2689 - val_mae: 1.2237\n",
      "Epoch 14/15\n",
      "41/41 [==============================] - 1s 32ms/step - loss: 0.2010 - mse: 0.2010 - mae: 0.2982 - val_loss: 2.2548 - val_mse: 2.2548 - val_mae: 1.2052\n",
      "Epoch 15/15\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.2891 - mse: 0.2891 - mae: 0.3813 - val_loss: 2.2975 - val_mse: 2.2975 - val_mae: 1.2326\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "history = model.fit(train_padded, train_labels, epochs=num_epochs, validation_data=(valid_padded, valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "14f4656c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 100, 32)           960000    \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 96, 128)           20608     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 980,737\n",
      "Trainable params: 980,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Conv1D(128, 5, activation='linear'),\n",
    "    tf.keras.layers.GlobalMaxPooling1D(),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "model.compile(loss='mse',optimizer='adam',metrics=['mse','mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c257102e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001613F614AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001613F614AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.2699 - mse: 2.2699 - mae: 1.3125WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001614426E048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001614426E048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 2.2699 - mse: 2.2699 - mae: 1.3125 - val_loss: 2.6863 - val_mse: 2.6863 - val_mae: 1.4090\n",
      "Epoch 2/15\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 2.0848 - mse: 2.0848 - mae: 1.2504 - val_loss: 2.4729 - val_mse: 2.4729 - val_mae: 1.3357\n",
      "Epoch 3/15\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 1.5712 - mse: 1.5712 - mae: 1.0405 - val_loss: 2.0812 - val_mse: 2.0812 - val_mae: 1.1876\n",
      "Epoch 4/15\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 1.0165 - mse: 1.0165 - mae: 0.7848 - val_loss: 1.9265 - val_mse: 1.9265 - val_mae: 1.1359\n",
      "Epoch 5/15\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.6746 - mse: 0.6746 - mae: 0.6172 - val_loss: 1.9029 - val_mse: 1.9029 - val_mae: 1.0986\n",
      "Epoch 6/15\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.4561 - mse: 0.4561 - mae: 0.4960 - val_loss: 1.9397 - val_mse: 1.9397 - val_mae: 1.0959\n",
      "Epoch 7/15\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.3373 - mse: 0.3373 - mae: 0.4179 - val_loss: 1.9094 - val_mse: 1.9094 - val_mae: 1.0813\n",
      "Epoch 8/15\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.2617 - mse: 0.2617 - mae: 0.3570 - val_loss: 1.9325 - val_mse: 1.9325 - val_mae: 1.0840\n",
      "Epoch 9/15\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.2296 - mse: 0.2296 - mae: 0.3299 - val_loss: 1.9422 - val_mse: 1.9422 - val_mae: 1.0804\n",
      "Epoch 10/15\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.1892 - mse: 0.1892 - mae: 0.2902 - val_loss: 1.9348 - val_mse: 1.9348 - val_mae: 1.0819\n",
      "Epoch 11/15\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1694 - mse: 0.1694 - mae: 0.2724 - val_loss: 1.9313 - val_mse: 1.9313 - val_mae: 1.0934\n",
      "Epoch 12/15\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1541 - mse: 0.1541 - mae: 0.2552 - val_loss: 1.9607 - val_mse: 1.9607 - val_mae: 1.0927\n",
      "Epoch 13/15\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.1313 - mse: 0.1313 - mae: 0.2250 - val_loss: 1.9390 - val_mse: 1.9390 - val_mae: 1.0901\n",
      "Epoch 14/15\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.1189 - mse: 0.1189 - mae: 0.2054 - val_loss: 1.9237 - val_mse: 1.9237 - val_mae: 1.0841\n",
      "Epoch 15/15\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.1090 - mse: 0.1090 - mae: 0.1941 - val_loss: 1.9484 - val_mse: 1.9484 - val_mae: 1.0921\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "history = model.fit(train_padded, train_labels, epochs=num_epochs, validation_data=(valid_padded, valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5aeb6176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000161442588B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000161442588B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1801790420332405"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "mean_absolute_error(test_labels,model.predict(testing_padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ae5931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eeba89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
