{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MOSI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCfW-y6nZr9P"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "from matplotlib.image import imread\n",
        "from google.colab import drive \n",
        "import os\n",
        "import tensorflow as tf\n",
        "import zipfile \n",
        "from numpy import asarray\n",
        "from numpy import save\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten, BatchNormalization,Activation,Dropout\n",
        "from keras.layers import Dense\n",
        "import keras\n",
        "from keras.layers import Conv2D, MaxPooling2D,MaxPool2D,AveragePooling2D,GlobalAveragePooling2D,MaxPooling1D\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.layers import Input, Flatten, Dense,BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras import Sequential\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn import metrics\n",
        "from keras import Sequential\n",
        "from matplotlib import pyplot as pt\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import initializers\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.initializers import *\n",
        "from keras.losses import binary_crossentropy\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import normalize\n",
        "import sklearn.metrics as metrics\n",
        "import random\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import glob\n",
        "import numpy as np\n",
        "from keras.callbacks import *\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "import re"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sizNHTtZ4qt"
      },
      "source": [
        "zip_ref1 = zipfile.ZipFile(\"/content/drive/MyDrive/Video.zip\", 'r')\n",
        "zip_ref1.extractall(\"/datalab\")\n",
        "zip_ref1.close()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKDLfWGJcPv7"
      },
      "source": [
        "trainpath = '/datalab/Video/Train'\n",
        "trainarr = os.listdir(trainpath)\n",
        "validpath = '/datalab/Video/Valid'\n",
        "validarr = os.listdir(validpath)\n",
        "testpath = '/datalab/Video/Test'\n",
        "testarr = os.listdir(testpath)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8DwsZm-dCRp",
        "outputId": "6ee84c4b-6db0-47c1-debe-c982f92f354f"
      },
      "source": [
        "i = 5\n",
        "b = re.findall('\\d*\\.?\\d+',trainarr[i])\n",
        "print(b)\n",
        "print(trainarr[i])\n",
        "c = trainarr[i].split(\"&\", 1)[-1][0]\n",
        "print(c)\n",
        "if c == \"-\":\n",
        "    b = float(b[-2])*-1\n",
        "else:\n",
        "    b = float(b[-2])\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0', '2', '2.80', '206']\n",
            "0h-zjBukYpk_2&-2.80&206.jpg\n",
            "-\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGHhEqixcw57"
      },
      "source": [
        "train = []\n",
        "train_labels = []\n",
        "for i in range(len (trainarr)):\n",
        "  myFile = os.path.join(trainpath, trainarr[i])\n",
        "  image = cv2.imread(myFile)\n",
        "  image1 = cv2.resize(image,(128,128), interpolation=cv2.INTER_CUBIC)\n",
        "  train.append(image1)\n",
        "  b = re.findall('\\d*\\.?\\d+',trainarr[i])\n",
        "  c = trainarr[i].split(\"&\", 1)[-1][0]\n",
        "  if c == \"-\":\n",
        "      b = float(b[-2])*-1\n",
        "  else:\n",
        "      b = float(b[-2])\n",
        "  train_labels.append(b)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ0V5bmxce7d"
      },
      "source": [
        "valid = []\n",
        "valid_labels = []\n",
        "for i in range(len (validarr)):\n",
        "  myFile = os.path.join(validpath, validarr[i])\n",
        "  image = cv2.imread(myFile)\n",
        "  image1 = cv2.resize(image,(128,128), interpolation=cv2.INTER_CUBIC)\n",
        "  valid.append(image1)\n",
        "  b = re.findall('\\d*\\.?\\d+',validarr[i])\n",
        "  c = validarr[i].split(\"&\", 1)[-1][0]\n",
        "  if c == \"-\":\n",
        "      b = float(b[-2])*-1\n",
        "  else:\n",
        "      b = float(b[-2])\n",
        "  valid_labels.append(b)\n",
        "  "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_C45Csxij75"
      },
      "source": [
        "test = []\n",
        "test_labels = []\n",
        "for i in range(len (testarr)):\n",
        "  myFile = os.path.join(testpath, testarr[i])\n",
        "  image = cv2.imread(myFile)\n",
        "  image1 = cv2.resize(image,(224,224), interpolation=cv2.INTER_CUBIC)\n",
        "  test.append(image1)\n",
        "  b = re.findall('\\d*\\.?\\d+',testarr[i])\n",
        "  c = testarr[i].split(\"&\", 1)[-1][0]\n",
        "  if c == \"-\":\n",
        "      b = float(b[-2])*-1\n",
        "  else:\n",
        "      b = float(b[-2])\n",
        "  test_labels.append(b)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqrkczuuZ6l2"
      },
      "source": [
        "train = np.asarray(train)\n",
        "train_labels = np.asarray(train_labels)\n",
        "valid = np.asarray(valid)\n",
        "valid_labels = np.asarray(valid_labels)\n",
        "test = np.asarray(test)\n",
        "test_labels = np.asarray(test_labels)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEoc9Mypm6Lf"
      },
      "source": [
        "train = train/255\n",
        "valid = valid/255\n",
        "test = test/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W08R_778nCSc"
      },
      "source": [
        "from keras.applications import VGG16\n",
        "#Load the VGG model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmw28uF5ilxa"
      },
      "source": [
        "for layer in base_model.layers[:-2]:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvRHnq0JiQyR"
      },
      "source": [
        "def define_model(base_model):\n",
        "    inputs1 = Input(shape=(None, None, 3,))\n",
        "    model = Sequential()\n",
        "    model.add(base_model)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1,activation = \"Linear\"))\n",
        "    print(model.summary())\n",
        "    plot_model(model, to_file='mode.png', show_shapes=True)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVp4MpZcitB5"
      },
      "source": [
        "model = define_model(base_model)\n",
        "model.compile(loss='mse',\n",
        "              optimizer='adam',\n",
        "              metrics=['mse','mae'])\n",
        "model.fit(train,train_labels, epochs = 10, validation_data = (valid,valid_labels))\n",
        "model.save('video_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6xXXcd-jJjO"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "mean_squared_error(test_labels,model.predict(test))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}